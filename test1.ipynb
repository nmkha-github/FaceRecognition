{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from keras_vggface import utils\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, Flatten, Layer, Conv2D, Lambda, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras.utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the training data\n",
    "Define the path to the face data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'face_data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the face images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for person_name in os.listdir(data_dir):\n",
    "    person_dir = os.path.join(data_dir, person_name)\n",
    "    for image_name in os.listdir(person_dir):\n",
    "        image_path = os.path.join(person_dir, image_name)\n",
    "        image = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "        X_train.append(tf.keras.utils.img_to_array(image))\n",
    "        y_train.append(person_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4].astype('uint8'), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(data_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the face images and labels to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label-encode the person names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ArcFace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArcFace Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLayer(Layer):\n",
    "    def __init__(self, num_classes, m=0.5, s=64.0, regularizer=None, **kwargs):\n",
    "        super(ArcFaceLayer, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.regularizer = regularizer\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], self.num_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True, \n",
    "                                 regularizer=self.regularizer,\n",
    "                                 name='W')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # normalize input features\n",
    "        x = tf.nn.l2_normalize(inputs, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product between features and weights\n",
    "        logits = tf.matmul(x, W)\n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArcFace loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcface_loss(y_true, y_pred, m=0.5, s=64.0):\n",
    "    # normalize input features\n",
    "    embeddings = tf.nn.l2_normalize(y_pred, axis=1)\n",
    "\n",
    "    # normalize weights\n",
    "    W = tf.nn.l2_normalize(tf.ones((embeddings.shape[1], y_true.shape[1])), axis=0)\n",
    "\n",
    "    # compute logits\n",
    "    logits = tf.matmul(embeddings, W)\n",
    "\n",
    "    # add margin\n",
    "    theta = tf.acos(tf.clip_by_value(logits, -1.0 + tf.keras.backend.epsilon(), 1.0 - tf.keras.backend.epsilon()))\n",
    "    target_logits = tf.cos(theta + m)\n",
    "\n",
    "    # multiply with scaling parameter\n",
    "    logits *= s\n",
    "\n",
    "    # apply cross-entropy loss\n",
    "    logits_softmax = tf.nn.softmax(logits, axis=-1)\n",
    "    ce_loss = tf.losses.categorical_crossentropy(y_true, logits_softmax)\n",
    "\n",
    "    # add the ArcFace margin loss\n",
    "    target_logits_softmax = tf.nn.softmax(target_logits, axis=-1)\n",
    "    arcface_loss = tf.losses.categorical_crossentropy(y_true, target_logits_softmax)\n",
    "\n",
    "    return ce_loss + arcface_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the VGG-Face model as the feature extraction backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = VGGFace(model='vgg16', include_top=False,\n",
    "                   input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the full face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import conv1d\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "     # Input layer\n",
    "    Input(shape=(224, 224, 3)),\n",
    "    \n",
    "    # Convolutional layers\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the features\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    ArcFaceLayer(num_classes=num_classes,\n",
    "            regularizer=regularizers.l2(0.01))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: compile model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=arcface_loss,\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   model = keras.models.load_model(os.getcwd())\n",
    "# except:\n",
    "#   print('error')\n",
    "#   pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the training labels to one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = keras.utils.np_utils.to_categorical(\n",
    "    y_train, num_classes=num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/520\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/520\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 2.7728 - accuracy: 0.5000 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/520\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 2.7728 - accuracy: 0.0000e+00 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/520\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/520\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 2.7728 - accuracy: 0.0000e+00 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/520\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/520\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/520\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 2.7728 - accuracy: 0.5000 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/520\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/520\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 2.7728 - accuracy: 0.0000e+00 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/520\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 2.7728 - accuracy: 0.5000 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/520\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/520\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 2.7728 - accuracy: 0.2500 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/520\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 2.7728 - accuracy: 0.5000 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/520\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 2.7728 - accuracy: 0.0000e+00 - val_loss: 2.7728 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/520\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 2.7728 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/520\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/520\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/520\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/520\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/520\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/520\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/520\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/520\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/520\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/520\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/520\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/520\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/520\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/520\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/520\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/520\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/520\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/520\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/520\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/520\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/520\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/520\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/520\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/520\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/520\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/520\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/520\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/520\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/520\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/520\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/520\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/520\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/520\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/520\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 2.7727 - accuracy: 0.0000e+00 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/520\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 2.7727 - accuracy: 0.2500 - val_loss: 2.7727 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/520\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 2.7727 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/520\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/520\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/520\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/520\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 63/520\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 64/520\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 65/520\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 66/520\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 67/520\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 68/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 69/520\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 70/520\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 71/520\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 72/520\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 73/520\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 74/520\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 75/520\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 76/520\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 77/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 78/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 79/520\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 80/520\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/520\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/520\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/520\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/520\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/520\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/520\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/520\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/520\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/520\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/520\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/520\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/520\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/520\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/520\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/520\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/520\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/520\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/520\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/520\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/520\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/520\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/520\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/520\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/520\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/520\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/520\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/520\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/520\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/520\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/520\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/520\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/520\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/520\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/520\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 120/520\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 121/520\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/520\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/520\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/520\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/520\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 126/520\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 127/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 128/520\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 129/520\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/520\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/520\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/520\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/520\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/520\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 135/520\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 136/520\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 137/520\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 138/520\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 139/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 140/520\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 141/520\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 142/520\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 143/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 144/520\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 145/520\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/520\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 148/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/520\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/520\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/520\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/520\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 154/520\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 155/520\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 156/520\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/520\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/520\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/520\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/520\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/520\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/520\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/520\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/520\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/520\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/520\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/520\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/520\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/520\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/520\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/520\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/520\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/520\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/520\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 175/520\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 176/520\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 177/520\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 178/520\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 179/520\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 180/520\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 181/520\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/520\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/520\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/520\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/520\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/520\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/520\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/520\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/520\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 190/520\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 191/520\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 192/520\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 193/520\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 194/520\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 195/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 196/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/520\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/520\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 204/520\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/520\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/520\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/520\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/520\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/520\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/520\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/520\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/520\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/520\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/520\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/520\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/520\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/520\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/520\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/520\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/520\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/520\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/520\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/520\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/520\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/520\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 229/520\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 230/520\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 231/520\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 232/520\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 233/520\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/520\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/520\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 236/520\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 237/520\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 238/520\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 239/520\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/520\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/520\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/520\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/520\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/520\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/520\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 246/520\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 247/520\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 248/520\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 249/520\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/520\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/520\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/520\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/520\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/520\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/520\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/520\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 257/520\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/520\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/520\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/520\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/520\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/520\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/520\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/520\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/520\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/520\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/520\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/520\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 271/520\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 272/520\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 273/520\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/520\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/520\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/520\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/520\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/520\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/520\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/520\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 281/520\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 282/520\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 283/520\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/520\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/520\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/520\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 287/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 288/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 289/520\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/520\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/520\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/520\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 293/520\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/520\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/520\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/520\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/520\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/520\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/520\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/520\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/520\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/520\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/520\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/520\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/520\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/520\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 308/520\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 309/520\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 310/520\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/520\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/520\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/520\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/520\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/520\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 316/520\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 317/520\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 318/520\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 319/520\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/520\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 321/520\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/520\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/520\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/520\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/520\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/520\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/520\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/520\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/520\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/520\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/520\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 332/520\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 333/520\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 334/520\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/520\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/520\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/520\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/520\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 339/520\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/520\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/520\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 342/520\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 343/520\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/520\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/520\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/520\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/520\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/520\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/520\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/520\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/520\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/520\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/520\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/520\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/520\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 356/520\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/520\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 358/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/520\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/520\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/520\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/520\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/520\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/520\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 369/520\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/520\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/520\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/520\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/520\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/520\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 375/520\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 376/520\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/520\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/520\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/520\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/520\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/520\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/520\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/520\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/520\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/520\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/520\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/520\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/520\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 389/520\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 390/520\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/520\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/520\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/520\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/520\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/520\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 399/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 400/520\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 402/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 403/520\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 404/520\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 405/520\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 406/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/520\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/520\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/520\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/520\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 411/520\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/520\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/520\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/520\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/520\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/520\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 417/520\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/520\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/520\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/520\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/520\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/520\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 423/520\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/520\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 425/520\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/520\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/520\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 428/520\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 429/520\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 430/520\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 431/520\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/520\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/520\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/520\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/520\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 437/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 438/520\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/520\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/520\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/520\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/520\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 443/520\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 444/520\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/520\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/520\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/520\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/520\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/520\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/520\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/520\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/520\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/520\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/520\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/520\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/520\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/520\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/520\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/520\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/520\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 462/520\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 463/520\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 464/520\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 465/520\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 466/520\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/520\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/520\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 470/520\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 471/520\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 472/520\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/520\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/520\n",
      "1/1 [==============================] - 1s 753ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 475/520\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 476/520\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 477/520\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/520\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 479/520\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 480/520\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 481/520\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 2.7726 - accuracy: 0.7500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/520\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/520\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/520\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/520\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/520\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/520\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/520\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/520\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/520\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/520\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/520\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/520\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/520\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/520\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 496/520\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 497/520\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/520\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/520\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/520\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 501/520\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/520\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/520\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 504/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 506/520\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 509/520\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 510/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/520\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.0000e+00 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/520\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 514/520\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/520\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/520\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 517/520\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 518/520\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/520\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 2.7726 - accuracy: 0.2500 - val_loss: 2.7726 - val_accuracy: 1.0000\n",
      "Epoch 520/520\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 2.7726 - accuracy: 0.5000 - val_loss: 2.7726 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d21b7bceb0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_onehot, batch_size=32,\n",
    "          epochs=10, validation_split=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[0.6675816  0.6033869  0.78126115 0.66552234]]\n",
      "Christian_Olsson\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "image_path = 'D:/PPNCKH/test/mk.jpg'\n",
    "image = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "x = tf.keras.utils.img_to_array(image)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x)\n",
    "\n",
    "# Use the trained model to make a prediction\n",
    "prediction = model.predict(x)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "print(label_encoder.inverse_transform(y_train)[np.argmax(prediction)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
